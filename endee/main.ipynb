{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-28T18:57:45.700311Z",
     "start_time": "2026-01-28T18:57:25.020956Z"
    }
   },
   "source": [
    "from endee import Endee\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhavy\\.conda\\envs\\Langchain\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T19:02:16.918888Z",
     "start_time": "2026-01-28T19:02:07.819314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loader = PyPDFLoader(r\"C:\\Users\\bhavy\\PycharmProjects\\PythonProject1\\llm.pdf\")\n",
    "docs=loader.load()"
   ],
   "id": "ba70ea4bfaf36163",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T19:02:24.449400Z",
     "start_time": "2026-01-28T19:02:24.378413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Text Splitters\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=50)\n",
    "chunks=text_splitter.split_documents(docs)"
   ],
   "id": "f3438cf7050d51",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T19:03:04.505011Z",
     "start_time": "2026-01-28T19:02:28.012062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Loading Embedding model\n",
    "model=SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "text=[doc.page_content for doc in chunks]\n",
    "vectors=model.encode(text)"
   ],
   "id": "c22ba89e6e923ba2",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T19:03:24.007541Z",
     "start_time": "2026-01-28T19:03:23.969355Z"
    }
   },
   "cell_type": "code",
   "source": "vectors",
   "id": "b741e1b0a1f05be4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0299766 , -0.05862331,  0.07544198, ...,  0.02781818,\n",
       "         0.02469181,  0.01118146],\n",
       "       [ 0.04924611, -0.08084214,  0.09697701, ..., -0.0180906 ,\n",
       "        -0.01246059, -0.03512884],\n",
       "       [ 0.03481973, -0.09109627,  0.01799844, ..., -0.02777154,\n",
       "        -0.11951374, -0.00536834],\n",
       "       ...,\n",
       "       [-0.0452126 , -0.01945757,  0.03190787, ..., -0.00194283,\n",
       "         0.02860099, -0.02823781],\n",
       "       [-0.02253441, -0.00456246,  0.01028754, ...,  0.04631921,\n",
       "         0.07505558, -0.05320664],\n",
       "       [-0.04532268,  0.04679902, -0.06417809, ..., -0.01675811,\n",
       "         0.00049432, -0.08918935]], shape=(603, 384), dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T19:03:36.778458Z",
     "start_time": "2026-01-28T19:03:36.739146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Connecting to Endee\n",
    "client=Endee()\n",
    "index=client.get_index(name=\"documents\")"
   ],
   "id": "276fdc6fa83c5b23",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T19:03:39.287942Z",
     "start_time": "2026-01-28T19:03:39.250073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "items = []\n",
    "for i, vec in enumerate(vectors):\n",
    "    items.append({\n",
    "    \"id\": f\"chunk_{i}\",\n",
    "    \"vector\": vec.tolist(),\n",
    "    \"meta\": {\n",
    "    \"text\": text[i],\n",
    "    \"page\": chunks[i].metadata.get(\"page\", 0),\n",
    "    \"source\": \"pdf\"\n",
    "    }\n",
    "    })"
   ],
   "id": "a526de0ab3ab7495",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T19:03:42.860120Z",
     "start_time": "2026-01-28T19:03:42.494350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "index.upsert(items)\n",
    "print(\"✅ PDF indexed using LangChain + Endee\")"
   ],
   "id": "6fda3795740a69b5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PDF indexed using LangChain + Endee\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T19:04:09.123425Z",
     "start_time": "2026-01-28T19:04:09.115422Z"
    }
   },
   "cell_type": "code",
   "source": "query = \"What is LLM\"",
   "id": "2ff6c4b5639d1e16",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "SEMANTIC SEARCH",
   "id": "9adf4222dc2ce426"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T19:04:10.916221Z",
     "start_time": "2026-01-28T19:04:10.798378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query_vec = model.encode([query])[0]\n",
    "results = index.query(vector=query_vec.tolist(), top_k=2)\n",
    "for r in results:\n",
    "    print(r[\"meta\"][\"text\"][:300])"
   ],
   "id": "2786b80e6308da37",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM research, it has become considerably challenging to perceive the bigger picture of the advances in this direction. Considering\n",
      "the rapidly emerging plethora of literature on LLMs, it is imperative that the research community is able to benefit from a concise\n",
      "yet comprehensive overview of the rec\n",
      "surveys in [54, 55, 56, 57, 58]. In contrast to these surveys, our\n",
      "contribution focuses on providing a comprehensive yet concise\n",
      "overview of the general direction of LLM research. This arti-\n",
      "cle summarizes architectural and training details of pre-trained\n",
      "LLMs and delves deeper into the details of c\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T19:04:51.179895Z",
     "start_time": "2026-01-28T19:04:51.155813Z"
    }
   },
   "cell_type": "code",
   "source": "query = \"What is Tokenizatiom\"",
   "id": "563ef65986d3ef1b",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T19:04:52.706671Z",
     "start_time": "2026-01-28T19:04:52.620871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query_vec = model.encode([query])[0]\n",
    "results = index.query(vector=query_vec.tolist(), top_k=2)\n",
    "for r in results:\n",
    "    print(r[\"meta\"][\"text\"][:300])"
   ],
   "id": "d25fc92113d57cec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Background\n",
      "We provide the relevant background to understand the fun-\n",
      "damentals related to LLMs in this section. We briefly discuss\n",
      "necessary components in LLMs and refer the readers interested\n",
      "in details to the original works.\n",
      "2.1. Tokenization\n",
      "Tokenization [59] is an essential pre-processing ste\n",
      "Next Token Standard - BPE+ Pre-LayerLearned GeLU - 96 96 12288ERNIE 3.0 (10B) Causal-Dec Next Token Standard - WordPiece Post-LayerRelative GeLU - 48 64 4096Jurassic-1 (178B) Causal-Dec Next Token Standard 256k SentencePiece∗ Pre-LayerLearned GeLU ✓ 76 96 13824HyperCLOV A (82B)Causal-Dec Next TokenD\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "RAG PIPELINE",
   "id": "9be9ca2585a83a89"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T19:25:02.371242Z",
     "start_time": "2026-01-28T19:24:59.180355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm=ChatOllama(model=\"gemma3:4b\")"
   ],
   "id": "f1c53804090df60a",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T19:39:56.710975Z",
     "start_time": "2026-01-28T19:39:56.687653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def ask_pdf(query,top_k=5):\n",
    "    query_vec = model.encode([query])[0]\n",
    "    results = index.query(vector=query_vec.tolist(),top_k=top_k)\n",
    "    context = \"\\n\\n\".join(r[\"meta\"][\"text\"] for r in results)\n",
    "    prompt = f\"\"\"\n",
    "    Answer the question using ONLY the context below.\n",
    "    If the answer is not in the context, say \"I don't know\".\n",
    "    Context:\n",
    "    {context}\n",
    "    Question:\n",
    "    {query}\n",
    "    \"\"\"\n",
    "    response=llm.invoke(prompt)\n",
    "    print(response.content)\n"
   ],
   "id": "86fba717b097da3a",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T19:41:44.635673Z",
     "start_time": "2026-01-28T19:39:59.592140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "q=\"What is Tokenization\"\n",
    "print(ask_pdf(q))\n"
   ],
   "id": "a08cb90e2bb8dee9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization [59] is an essential pre-processing step in LLM training that parses the text into non-decomposing units called tokens. Tokens can be characters, subwords, symbols, or words, depending on the tokenization process.\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T19:43:46.840786Z",
     "start_time": "2026-01-28T19:42:19.821736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "q=\"What is Self Attention\"\n",
    "print(ask_pdf(q))"
   ],
   "id": "b2a36184d9c060e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self-attention has O(n2) time complexity which becomes infeasible for large sequences. To speed up the computation, sparse attention iteratively calculates attention in sliding windows for speed gains.\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T19:48:01.510666Z",
     "start_time": "2026-01-28T19:47:02.005494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "q=\"What is LLM\"\n",
    "print(ask_pdf(q))"
   ],
   "id": "b180176d0641b30f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLMs can play user-defined roles and behave like a specific domain expert. In multi-agent systems, each LLM is assigned a unique role, simulating human behavior and collaborating with other agents to complete a complex task.\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "de5d401b44315d72"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
